{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff62317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Dict, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "import os.path as op\n",
    "\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import entropy\n",
    "from pysankey2 import Sankey\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from cluster import reindex_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde48928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join similarity matrices - should only need to run once\n",
    "def join_similarities():\n",
    "    sim_paths = Path('../data/similarity/')\n",
    "\n",
    "    df_similarity = None\n",
    "    for f in sim_paths.rglob('*h5'):\n",
    "        dataset, atlas = str(f).split('/')[-1].split('_')[0:2]\n",
    "        tdf = pd.read_hdf(f)\n",
    "        tdf['dataset'], tdf['atlas'] = dataset, atlas\n",
    "\n",
    "        if df_similarity is None:\n",
    "            df_similarity = tdf\n",
    "        else:\n",
    "            df_similarity = pd.concat([df_similarity, tdf])\n",
    "\n",
    "    pd.to_pickle(df_similarity, '../data/clustering/preprocessed_similarity.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca6f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ClusteringFrames:\n",
    "    definitions: Optional[pd.DataFrame] = None\n",
    "    data: Optional[pd.DataFrame] = None\n",
    "    subjects: Optional[pd.DataFrame] = None\n",
    "    overlap: Optional[pd.DataFrame] = None\n",
    "    plot: Optional[Any] = None\n",
    "    combinations: List = field(default_factory=list)\n",
    "    sorting: Dict = field(default_factory=lambda: {})\n",
    "    plot_order: List = field(default_factory=lambda: ['aal', 'cc2', 'hox', 'des'])\n",
    "\n",
    "\n",
    "# Utility function to slice dataframes\n",
    "def get_df_slice(df, ds, at):\n",
    "    return df[(df['dataset'] == ds) & (df['atlas'] == at)]\n",
    "\n",
    "\n",
    "# Utility function to get and stack cluster signatures\n",
    "def get_signatures(df, c):\n",
    "    return np.stack([np.reshape(_, -1) for _ in get_df_slice(df, *c)['signature']])\n",
    "\n",
    "\n",
    "def compare_clustering(cluster_definitions: pd.DataFrame, cluster_data: pd.DataFrame,\n",
    "                       subject_similarity: pd.DataFrame, dataset: str, across: str=\"atlas\",\n",
    "                       plot: bool=True):\n",
    "    if across != \"atlas\":\n",
    "        raise NotImplementedError(\"Only across atlas comparisons are currently supported.\")\n",
    "\n",
    "    # Create data class for clustering informations\n",
    "    cf = ClusteringFrames()\n",
    "\n",
    "    # Reduce dataframe to only contain dataset of interest\n",
    "    cf.definitions = cluster_definitions[cluster_definitions['dataset'] == dataset]\n",
    "    cf.data = cluster_data[cluster_data['dataset'] == dataset]\n",
    "    cf.subjects = subject_similarity[subject_similarity['dataset'] == dataset]\n",
    "    \n",
    "    # Set up some convenience variables and lambdas\n",
    "    da = ['dataset', 'atlas']  # Regularly used for subsampling dataframe\n",
    "    cois = ['subject', 'session', 'dataset', 'atlas']  # Used to subsample subject dataframe\n",
    "    cf.combinations = cf.definitions.value_counts(da).index  # Is sorted in order of most->fewest clusters \n",
    "\n",
    "    # Extract info from reference parcellation (the one with the most clusters)\n",
    "    dataset_atlas = cf.combinations[0]\n",
    "    sig_ref = get_signatures(cf.definitions, dataset_atlas)\n",
    "    cf.sorting[dataset_atlas[1]] = np.arange(len(sig_ref)) # dataset_atlas[1] is the atlas name\n",
    "\n",
    "    # Set up subject matrix for cluster assignment, and populate with reference\n",
    "    cf.subjects = cf.subjects[cois].groupby(['subject', 'session']).max()\n",
    "    labels = get_df_slice(cf.data, *dataset_atlas)['labels'].values[0]\n",
    "    cf.subjects[dataset_atlas[1]] = reindex_clusters(labels, order=cf.sorting[dataset_atlas[1]])\n",
    "\n",
    "    # Match clusters from other parcellations\n",
    "    for idx, da2 in enumerate(cf.combinations[1:]):\n",
    "        # da2 = dataset_atlas_2\n",
    "        sig_targ = get_signatures(cf.definitions, da2)\n",
    "\n",
    "        # Compute similarity of clusters, and match them\n",
    "        cost = cdist(sig_ref, sig_targ, metric='cosine')\n",
    "        reorder = linear_sum_assignment(cost)\n",
    "        cf.sorting[da2[1]] = np.argsort(reorder[1])\n",
    "\n",
    "        # Assign cluster memberships (with updated indice) back to subjects/sessions\n",
    "        labels = get_df_slice(cf.data, *da2)['labels'].values[0]\n",
    "        cf.subjects[da2[1]] = reindex_clusters(labels, order=cf.sorting[da2[1]])\n",
    "\n",
    "    # Create utility dataframes and perform Sankey plotting\n",
    "    if plot:\n",
    "        # Set colourmap for plot\n",
    "        cm = [\"#9d973f\", \"#b253c0\", \"#64ac48\", \"#6768cc\", \"#c67f40\", \"#5d94ce\",\n",
    "              \"#d04a3e\", \"#4aac8b\", \"#d14788\", \"#bb7fc1\", \"#bb6271\"]\n",
    "        # From : http://medialab.github.io/iwanthue/\n",
    "        \n",
    "        # Rename columns and establish the (sequential) sorting of clusters\n",
    "        col_names = {atlas: 'layer'+str(_+1)\n",
    "                     for _, atlas in enumerate(cf.plot_order)}\n",
    "        cords = {'layer'+str(_+1): np.arange(len(cf.sorting[atlas]))\n",
    "                 for _, atlas in enumerate(cf.plot_order)}\n",
    "        \n",
    "        # Create a slimmed down dataframe for Sankey\n",
    "        sankey_df = cf.subjects[cf.plot_order]\n",
    "        sankey_df = sankey_df.rename(columns=col_names)\n",
    "        sankey_df = sankey_df.reset_index().drop(columns=['subject', 'session'])\n",
    "\n",
    "        color_dict = {_: cm[_] for _ in range(len(sig_ref))}\n",
    "        \n",
    "        # Plot\n",
    "        cf.plot = Sankey(sankey_df, colorMode='global', stripColor='gray', colorDict=color_dict, layerLabels=cords)\n",
    "        fig, ax = cf.plot.plot(figSize=(15, 15), fontSize=0)\n",
    "        plt.title(dataset_atlas[0])\n",
    "        fig.show()\n",
    "\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d03fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_def = pd.read_pickle('../data/clustering/cluster_definitions.pkl')\n",
    "df_cluster_dat = pd.read_pickle('../data/clustering/cluster_membership.pkl')\n",
    "if not op.exists('../data/clustering/preprocessed_similarity.pkl'):\n",
    "    join_similarities()\n",
    "df_similarity = pd.read_pickle('../data/clustering/preprocessed_similarity.pkl')\n",
    "\n",
    "datasets = sorted(df_cluster_def['dataset'].unique())\n",
    "def cc_easy(dataset, **kwargs):\n",
    "    return compare_clustering(df_cluster_def, df_cluster_dat, df_similarity, dataset, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8524886e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cf = {}\n",
    "for d in datasets:\n",
    "    cf[d] = cc_easy(d, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c57608bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_session_variation(clusterframe):\n",
    "    tdf = []\n",
    "    for atlas, labels in clusterframe.sorting.items():\n",
    "        ents = []\n",
    "        for name, group in clusterframe.subjects.groupby('subject'):\n",
    "            counts = group.value_counts(normalize=True, subset=[atlas])\n",
    "            bins = [0] * len(labels)\n",
    "            for k, v in counts.items():\n",
    "                bins[k[0]] = v\n",
    "            ents += [entropy(bins)]\n",
    "        ent_hat = np.mean(ents)\n",
    "        ent_bar = ent_hat / entropy([1.0/len(labels)] * len(labels))\n",
    "        tdf += [{\n",
    "            \"dataset\": group.dataset,\n",
    "            \"atlas\": atlas,\n",
    "            \"n_classes\": len(labels),\n",
    "            \"entropy\": ent_hat,\n",
    "            \"normalized_entropy\": ent_bar\n",
    "        }]\n",
    "    return tdf\n",
    "\n",
    "\n",
    "def compute_atlas_variation(clusterframe):\n",
    "    tdf = []\n",
    "    for idx, da1 in enumerate(clusterframe.combinations):\n",
    "        for jdx, da2 in enumerate(clusterframe.combinations[idx+1:]):\n",
    "            l1 = get_df_slice(clusterframe.data, *da1).labels.values[0]\n",
    "            l2 = get_df_slice(clusterframe.data, *da2).labels.values[0]\n",
    "            tmp = l1 == l2\n",
    "\n",
    "            tdf += [{\n",
    "                \"dataset\": da1[0],\n",
    "                \"atlas1\": da1[1],\n",
    "                \"atlas2\": da2[1],\n",
    "                \"ARI\": adjusted_rand_score(l1, l2),\n",
    "                \"AMI\": adjusted_mutual_info_score(l1, l2),\n",
    "                \"Percent Overlap\": np.sum(tmp)/len(tmp)*100\n",
    "            }]\n",
    "    return tdf\n",
    "\n",
    "\n",
    "tdf_s = []\n",
    "tdf_a = []\n",
    "# Perform some post-processing for the datasets all together\n",
    "for d in datasets:\n",
    "    # Extract the relevant clustering (data)frames collection\n",
    "    tcf = cf[d]\n",
    "    \n",
    "    # Compute the variation in cluster membership across sessions\n",
    "    is_trt = len(tcf.subjects.index.unique(level='subject')) < len(tcf.subjects.index)\n",
    "    if is_trt:\n",
    "        tdf_s += compute_session_variation(tcf)\n",
    "\n",
    "    # Compute the variation in cluster membership across atlases\n",
    "    tdf_a += compute_atlas_variation(tcf)\n",
    "\n",
    "session_overlap = pd.DataFrame.from_dict(tdf_s)\n",
    "atlas_overlap = pd.DataFrame.from_dict(tdf_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e467464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_classes</th>\n",
       "      <th>entropy</th>\n",
       "      <th>normalized_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.442308</td>\n",
       "      <td>0.453783</td>\n",
       "      <td>0.335217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.852979</td>\n",
       "      <td>0.208785</td>\n",
       "      <td>0.156454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.077016</td>\n",
       "      <td>0.082248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.315067</td>\n",
       "      <td>0.243005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.421614</td>\n",
       "      <td>0.315465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.523252</td>\n",
       "      <td>0.388826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.259972</td>\n",
       "      <td>0.957544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_classes     entropy  normalized_entropy\n",
       "count  104.000000  104.000000          104.000000\n",
       "mean     4.442308    0.453783            0.335217\n",
       "std      1.852979    0.208785            0.156454\n",
       "min      2.000000    0.077016            0.082248\n",
       "25%      3.000000    0.315067            0.243005\n",
       "50%      4.000000    0.421614            0.315465\n",
       "75%      5.000000    0.523252            0.388826\n",
       "max     11.000000    1.259972            0.957544"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_overlap.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a1cf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARI</th>\n",
       "      <th>AMI</th>\n",
       "      <th>Percent Overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.190582</td>\n",
       "      <td>0.232728</td>\n",
       "      <td>36.706510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.133218</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>18.385048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.070962</td>\n",
       "      <td>0.032306</td>\n",
       "      <td>5.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.152377</td>\n",
       "      <td>21.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.176414</td>\n",
       "      <td>0.224182</td>\n",
       "      <td>33.949153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.253249</td>\n",
       "      <td>0.300838</td>\n",
       "      <td>49.215909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.742516</td>\n",
       "      <td>0.628475</td>\n",
       "      <td>93.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ARI         AMI  Percent Overlap\n",
       "count  162.000000  162.000000       162.000000\n",
       "mean     0.190582    0.232728        36.706510\n",
       "std      0.133218    0.110417        18.385048\n",
       "min     -0.070962    0.032306         5.769231\n",
       "25%      0.095844    0.152377        21.750000\n",
       "50%      0.176414    0.224182        33.949153\n",
       "75%      0.253249    0.300838        49.215909\n",
       "max      0.742516    0.628475        93.333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas_overlap.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648162c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-General",
   "language": "python",
   "name": "gp38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "30fe4a60b87ec2d41294748ca47e2c5a243a3fb878b670136a8e0787fab3fbed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
